{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno emplearemos la técnica de regresión linear (*Linear Regression*) para entrenar un modelo capaz de predecir el precio de listados basado en otras características de los mismos.\n",
    "\n",
    "La regresión linear es una de las formas más básicas de resolución de funciones de optimización mediante coeficientes. RAPIDS provee múltiples tipos de regresión simple, tales como *Logistic Regression*, *Ridge Regression* y *Lasso Regression*. Todos estos modelos comparten las mismas características de interfaz: customización de hiperparámetros, entrenamiento y predicción de un conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: Regresión por GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones\n",
    "* **os** y **os.path**: importan utilidades de Python para tratamiento de ficheros y comprobación de rutas.\n",
    "* **cudf**, **cupy** y **cuml**: librerías de RAPIDS.\n",
    "* **pandas** y **numpy**: librerías de manejo de DataFrames y gestión numérica, de vectores y tablas. Equivalentes a cudf y cupy respectivamente para CPU.\n",
    "* **sklearn**: librería de manejo de modelos machine learning, equivalente de cuml en CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import cuml\n",
    "from cuml.metrics.regression import mean_squared_error as mnsq\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mnsq_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ficheros de utilidades:\n",
    "* **f_northing**: conversión de coordenadas latitud-longitud a norte-este, empleados en manejo de mapas y coordenadas.\n",
    "* **f_northing_numpy**: equivalente de f_northing para estructuras de numpy.\n",
    "* **f_price_range**: normalización de precios en rangos establecidos manualmente. Necesario para clasificación multiclase, no necesario para regresión (aunque representa una versión simplificada o normalizada del objetivo a resolver).\n",
    "* **f_static_data**: funciones para cargar listas de datos estáticos, tales como nombres de ciudades a utilizar desde el directorio /data, columnas a leer por cada fichero CSV, y columnas a usar en el entrenamiento del modelo.\n",
    "* **f_utils**: utilidades de conversión de datos a tipos float32/float64, limpiado de strings de precios, factorización de columnas complejas en mapas numéricos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/f_northing.py\n",
    "%run ../utils/f_northing_numpy.py\n",
    "%run ../utils/f_price_range.py\n",
    "%run ../utils/f_static_data.py\n",
    "%run ../utils/f_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de datos:\n",
    "* **cities_to_use**: lista de directorios dentro de /data sobre los que leer datasets en formato CSV. Cada directorio es una ciudad, área, estado o país.\n",
    "* **columns_to_use**: lista de columnas a leer dentro de cada CSV. Todas las columnas deben existir y sus nombres deben coincidir.\n",
    "* **columns_to_fit**: lista de columnas a utilizar para el entrenamiento de modelos de machine learning. Nos permite hacer múltiples usos de un dataset sin necesidad de leerlo de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_to_use = ['sevilla']\n",
    "#cities_to_use = ['shanghai']\n",
    "#cities_to_use = cities_to_use_1()\n",
    "#cities_to_use = cities_to_use_2()\n",
    "columns_to_use = columns_to_use()\n",
    "columns_to_fit = columns_to_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo **set_global_output_type** de cuml determina la salida de datos de las funciones de cuml. La opción 'cudf' devuelve tipos de datos que cumplen con la especificación de RAPIDS: cudf.DataFrame y Series.\n",
    "\n",
    "Otros posibles valores (v0.18) son 'input' para mantener el formato de entrada, 'cupy' y 'numpy' para usar los formatos de las librerías correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuml.set_global_output_type('cudf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataFrame **listings** representa el conjunto de datos final sobre el que realizar operaciones de ciencia de datos o machine learning. Por cada directorio de datos, leemos todos los ficheros CSV disponibles y los agregamos a **listings**.\n",
    "* **standard_object_type**: algunas columnas no tienen un formato único de datos; esto puede deberse a diferentes departamentos o metodologías empleadas durante los varios *scraping* de datos de la fuente. Esta función convierte columnas (detectadas manualmente a priori) en tipo genérico *object*, que después convertiremos a un tipo de datos más apropiado para nuestro uso.\n",
    "* **drop_duplicates**: dado que utilizamos múltiples *datasets* por ciudades, hay listados de AirBnB que no cambian durante varios meses. En este caso, no necesitamos datos redundantes, y los removemos del DataFrame final.\n",
    "* **reset_index**: los datos de cada fichero se han unido mediante un DataFrame diferente, y por lo tanto los índices del DataFrame quedan mezclados al final del proceso. Con esta instrucción forzamos el índice de **listings** a ordenarse. La instrución añade una columna adicional con el índice antiguo, que podemos obviar con el parámetro drop=**True**.\n",
    "* **shape**: instrucción que devuelve el tamaño completo del DataFrame en formato (filas, columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = cudf.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df = cudf.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if(temp_df['host_total_listings_count'].dtype != 'float64'):\n",
    "                    temp_df['host_total_listings_count'] = temp_df['host_total_listings_count'].fillna(-1).astype('float64')\n",
    "                if(temp_df['bathrooms'].dtype != 'float64'):\n",
    "                    temp_df['bathrooms'] = temp_df['bathrooms'].fillna(-1).astype('float64')\n",
    "                if(temp_df['bedrooms'].dtype != 'float64'):\n",
    "                    temp_df['bedrooms'] = temp_df['bedrooms'].fillna(-1).astype('float64')\n",
    "                if(temp_df['beds'].dtype != 'float64'):\n",
    "                    temp_df['beds'] = temp_df['beds'].fillna(-1).astype('float64')\n",
    "                if listings.size == 0:\n",
    "                    listings = temp_df\n",
    "                else:\n",
    "                    for column in listings.columns:\n",
    "                        if listings[column].dtype != temp_df[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings[column].dtype.name+' doesnt match '+temp_df[column].dtype.name)\n",
    "                    listings = listings.append(temp_df)\n",
    "                    \n",
    "listings = listings.drop_duplicates()\n",
    "listings = listings.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento simple:\n",
    "* **type_conversion**: convertimos todas las columnas a un tipo de datos común: *float32* y *float64* son los más aceptados por los algoritmos de RAPIDS.\n",
    "* **column_factorize**: dado que algunos algoritmos no suportan datos no numéricos, factorizamos las columnas de texto. La operación factorize() convierte una columna con valores no numéricos a un mapa en el que cada valor único se representa por un integer. En nuestro caso, no necesitaremos el mapa que reconoce cada valor, pero es posible usarlo para devolver formato a los datos de cara a estudio o representación.\n",
    "\n",
    "Utilizamos versiones de tipo float64 para guardar el mayor grado posible de precisión sobre los valores numéricos, lo cual es deseable en  modelos de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_conversion_64(listings, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month', 'minimum_nights', 'maximum_nights', 'availability_30', 'availability_90', 'availability_365', 'number_of_reviews_ltm', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds'])\n",
    "column_factorize_64(listings, ['neighbourhood_cleansed', 'host_response_time', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'property_type', 'room_type', 'instant_bookable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento de cadenas:\n",
    "* **clean_format_strings**: eliminamos el carácter '%' de campos que lo contienen, y convertimos el valor resultante a *float32*.\n",
    "* **clean_format_price**: similar a la función anterior, pero eliminando caracteres de moneda (en nuestro caso, '$' y la coma de cantidades numéricas).\n",
    "* **applyMap**: aplica una función sucesivamente a todos los valores de la columna indicada. Utilizaremos la función **priceRange** para normalizar los precios en rangos, a fin de simplificar el ejemplo. Esta normalización permite que el *dataset* pueda usarse para clasificación multiclase y regresión (con un margen potencial de error mayor que si empleamos los valores de precio originales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_format_strings_64(listings, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price_64(listings, ['price'])\n",
    "listings['price'] = listings['price'].applymap(priceRange, 'float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fin de visualizar los datos en un formato 2D similar a un mapa, convertimos las coordatas latitud-longitud en distancias norte-este, y les asignamos columnas nuevas.\n",
    "\n",
    "El código necesario para visualizar datos se encuentra en el fichero *nb1_visual.ipynb*, Sección 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_lat = cp.asarray(listings['latitude'])\n",
    "cupy_long = cp.asarray(listings['longitude'])\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "listings['northing'] = cudf.Series(n_cupy_array).astype('float64')\n",
    "listings['easting'] = cudf.Series(e_cupy_array).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de las primeras 5 filas, para verificar el tratamiento de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de modelo de regresión para predicción de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de regresión linear entrenan un conjunto X de columnas de datos sobre los valores de un destino y, que es una columna singular con el valor a optimizar.\n",
    "\n",
    "Funciones:\n",
    "* **train_test_split**: funcion que toma un conjunto de datos y los separa en datos de entrenamiento y datos de prueba. Esto nos permite realizar predicciónes sin separar previamente los datos. El parámetro **train_size** indica qué porcentaje debería dedicarse a entrenamiento, en nuestro caso 0.9 = 90%.\n",
    "* **fit**: entrena el modelo sobre el conjunto *(X,y)* indicado. El modelo resultante puede ser reutilizado para predecir valores múltiples veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regression = cuml.LinearRegression()\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los coeficientes de cada variable de entrada en X sobre el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_map = cudf.DataFrame()\n",
    "coef_map['key'] = columns_to_fit\n",
    "coef_map['value'] = regression.coef_\n",
    "print(\"Coefficients:\")\n",
    "coef_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de predicciones sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = regression.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **mean_squared_error (mnsq)**: calcula el error cuadrático medio sobre los valores de las columnas indicadas. Podemos ver así el error total de las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mnsq(y_test_index, predictions)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2: Regresión por CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lectura y tratamiento de los datos iniciales sigue el mismo proceso que para GPU:\n",
    "1. Creamos un nuevo DataFrame vacío.\n",
    "2. Recorremos los directorios disponibles.\n",
    "3. Agregamos los CSV, convirtiendo columnas dispares a tipo *object* si fuera necesario.\n",
    "4. Eliminamos duplicados.\n",
    "5. Reordenamos el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings_cpu = pd.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df_cpu = pd.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df_cpu, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if(temp_df_cpu['host_total_listings_count'].dtype != 'float64'):\n",
    "                    temp_df_cpu['host_total_listings_count'] = temp_df_cpu['host_total_listings_count'].fillna(\"-1\").astype('float64')\n",
    "                if(temp_df_cpu['bathrooms'].dtype != 'float64'):\n",
    "                    temp_df_cpu['bathrooms'] = temp_df_cpu['bathrooms'].fillna(\"-1\").astype('float64')\n",
    "                if(temp_df_cpu['bedrooms'].dtype != 'float64'):\n",
    "                    temp_df_cpu['bedrooms'] = temp_df_cpu['bedrooms'].fillna(\"-1\").astype('float64')\n",
    "                if(temp_df_cpu['beds'].dtype != 'float64'):\n",
    "                    temp_df_cpu['beds'] = temp_df_cpu['beds'].fillna(\"-1\").astype('float64')\n",
    "                if listings_cpu.size == 0:\n",
    "                    listings_cpu = temp_df_cpu\n",
    "                else:\n",
    "                    for column in listings_cpu.columns:\n",
    "                        if listings_cpu[column].dtype != temp_df_cpu[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings_cpu[column].dtype.name+' doesnt match '+temp_df_cpu[column].dtype.name)\n",
    "                    listings_cpu = listings_cpu.append(temp_df_cpu)\n",
    "                    \n",
    "listings_cpu = listings_cpu.drop_duplicates()\n",
    "listings_cpu = listings_cpu.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones **type_conversion**, **column_factorize**, **clean_format_strings** y **priceRange** son las mismas empleadas para GPU, ya que las operaciones subyacentes tienen la misma semántica y uso para cuDF/cupy como para pandas/numpy.\n",
    "\n",
    "* **clean_format_price_cpu**: versión específica del tratado de cadenas de precios para CPU. Es necesario cambiar ligeramente el órden y número de operaciones para que numpy pueda ejecutar el mismo reemplazo de cadenas de precios que en GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_conversion_64(listings_cpu, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month', 'minimum_nights', 'maximum_nights', 'availability_30', 'availability_90', 'availability_365', 'number_of_reviews_ltm', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds'])\n",
    "column_factorize_64(listings_cpu, ['neighbourhood_cleansed', 'host_response_time', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'property_type', 'room_type', 'instant_bookable'])\n",
    "\n",
    "clean_format_strings_64(listings_cpu, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price_64_cpu(listings_cpu, ['price'])\n",
    "listings_cpu['price'] = listings_cpu['price'].apply(priceRange, 'float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única diferencia en la conversión de coordenadas latitud-logitud a norte-este es que utilizamos funciones aritméticas provistas por numpy en lugar de cupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_lat = listings_cpu['latitude'].to_numpy()\n",
    "numpy_long = listings_cpu['longitude'].to_numpy()\n",
    "n_numpy_array, e_numpy_array = latlong2osgbgrid_numpy(numpy_lat, numpy_long)\n",
    "listings_cpu['northing'] = pd.Series(n_numpy_array).astype('float64')\n",
    "listings_cpu['easting'] = pd.Series(e_numpy_array).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cpu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de modelo de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación del algoritmo de división de conjuntos de entrenamiento y prueba, así como la implementación de regresión linear por parte de scikit-learn, lectura de coeficientes, predicciones y métricas de error en este ejemplo son idénticas a las empleadas por RAPIDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linreg_cpu = LinearRegression()\n",
    "x_train_cpu, x_test_cpu, y_train_cpu, y_test_cpu  = train_test_split(listings_cpu[columns_to_fit], listings_cpu['price'], train_size=0.9)\n",
    "x_test_cpu_index = x_test_cpu.reset_index(drop=True)\n",
    "y_test_cpu_index = y_test_cpu.reset_index(drop=True)\n",
    "linreg_cpu.fit(x_train_cpu, y_train_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coef_map_cpu = pd.DataFrame()\n",
    "coef_map_cpu['key'] = columns_to_fit\n",
    "coef_map_cpu['value'] = linreg_cpu.coef_\n",
    "print(\"Coefficients:\")\n",
    "coef_map_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions_cpu = linreg_cpu.predict(x_test_cpu_index)\n",
    "y_results_cpu = pd.DataFrame()\n",
    "y_results_cpu['prediction'] = predictions_cpu\n",
    "y_results_cpu['real'] = y_test_cpu_index\n",
    "y_results_cpu[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cpu = mnsq_cpu(y_test_cpu_index, predictions_cpu)\n",
    "print(loss_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
