{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otras técnicas soportadas por RAPIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import cuml\n",
    "from cuml.linear_model import LogisticRegression, MBSGDClassifier, MBSGDRegressor\n",
    "from cuml.multiclass import MulticlassClassifier\n",
    "from cuml.naive_bayes import MultinomialNB\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.svm import SVC\n",
    "from cuml.metrics.regression import mean_squared_error as mnsq\n",
    "\n",
    "%run ../utils/f_northing.py\n",
    "%run ../utils/f_northing_numpy.py\n",
    "%run ../utils/f_price_range.py\n",
    "%run ../utils/f_static_data.py\n",
    "%run ../utils/f_utils.py\n",
    "\n",
    "cities_to_use = ['sevilla']\n",
    "#cities_to_use = ['shanghai']\n",
    "#cities_to_use = cities_to_use_1()\n",
    "#cities_to_use = cities_to_use_2()\n",
    "columns_to_use = columns_to_use()\n",
    "columns_to_fit = columns_to_fit()\n",
    "\n",
    "cuml.set_global_output_type('cudf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings = cudf.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df = cudf.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if(temp_df['host_total_listings_count'].dtype != 'float32'):\n",
    "                    temp_df['host_total_listings_count'] = temp_df['host_total_listings_count'].fillna(-1).astype('float32')\n",
    "                if(temp_df['bathrooms'].dtype != 'float32'):\n",
    "                    temp_df['bathrooms'] = temp_df['bathrooms'].fillna(-1).astype('float32')\n",
    "                if(temp_df['bedrooms'].dtype != 'float32'):\n",
    "                    temp_df['bedrooms'] = temp_df['bedrooms'].fillna(-1).astype('float32')\n",
    "                if(temp_df['beds'].dtype != 'float32'):\n",
    "                    temp_df['beds'] = temp_df['beds'].fillna(-1).astype('float32')\n",
    "                if listings.size == 0:\n",
    "                    listings = temp_df\n",
    "                else:\n",
    "                    for column in listings.columns:\n",
    "                        if listings[column].dtype != temp_df[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings[column].dtype.name+' doesnt match '+temp_df[column].dtype.name)\n",
    "                    listings = listings.append(temp_df)\n",
    "                    \n",
    "listings = listings.drop_duplicates()\n",
    "listings = listings.reset_index(drop=True)\n",
    "\n",
    "type_conversion(listings, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month', 'minimum_nights', 'maximum_nights', 'availability_30', 'availability_90', 'availability_365', 'number_of_reviews_ltm', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds'])\n",
    "column_factorize(listings, ['neighbourhood_cleansed', 'host_response_time', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'property_type', 'room_type', 'instant_bookable'])\n",
    "\n",
    "clean_format_strings(listings, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price(listings, ['price'])\n",
    "listings['price'] = listings['price'].applymap(priceRange, 'float32')\n",
    "listings['price'] = listings['price'].astype('float32')\n",
    "\n",
    "cupy_lat = cp.asarray(listings['latitude'])\n",
    "cupy_long = cp.asarray(listings['longitude'])\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "listings['northing'] = cudf.Series(n_cupy_array).astype('float32')\n",
    "listings['easting'] = cudf.Series(e_cupy_array).astype('float32')\n",
    "\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que la operación sort de cupy (basada en numpy.sort) tiene un límite estricto de elementos, ya sea por tamaño o por memoria disponible.\n",
    "\n",
    "Tomamos una sección del dataset con exactamente 5405 filas y ejecutamos un clasificador RandomForest multiclase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_section = listings[0:5405]\n",
    "\n",
    "cuml_model = RandomForestClassifier(max_features=1.0,\n",
    "                   n_bins=8,\n",
    "                   n_estimators=40)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings_section[columns_to_fit], listings_section['price'], train_size=0.9)\n",
    "\n",
    "cuml_model.fit(x_train,y_train)\n",
    "cuml_predict = cuml_model.predict(x_test)\n",
    "\n",
    "print(\"Predicted labels : \", cuml_predict[0:10])\n",
    "print(\"Real : \", y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos el mismo clasificador con una fila más:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_section = listings[0:5406]\n",
    "\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings_section[columns_to_fit], listings_section['price'], train_size=0.9)\n",
    "\n",
    "cuml_model.fit(x_train,y_train)\n",
    "cuml_predict = cuml_model.predict(x_test)\n",
    "\n",
    "print(\"Predicted labels : \", cuml_predict[0:10])\n",
    "print(\"Real : \", y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible ver una traza de error más detallada si, en lugar de ejecutar el caso anterior, se ejecuta el siguiente caso con un dataset generado aleatoriamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cp.random.normal(size=(5406,4)).astype(np.float32)\n",
    "y = cp.random.randint(2,size=(5406,1)).astype(np.int32)\n",
    "\n",
    "cuml_model = RandomForestClassifier(max_features=1.0,\n",
    "                   n_bins=8,\n",
    "                   n_estimators=40)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(X, y, train_size=0.9)\n",
    "\n",
    "cuml_model.fit(x_train,y_train)\n",
    "cuml_predict = cuml_model.predict(x_test)\n",
    "\n",
    "print(\"Predicted labels : \", cuml_predict[0:10])\n",
    "print(\"Real : \", y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado es dependiente de la memoria disponible en el sistema: los ejemplos anteriores se han realizado sobre una tarjeta gráfica NVIDIA GTX 1060 con 6GB de VRAM, mientras que en una GPU Tesla V100 con 16GB de VRAM no se producen errores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación/Regresión mediante SGD/MiniBatch SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de esta familia producen resultados varios según se traten de regresión o clasificación.\n",
    "\n",
    "El clasificador MiniBatch produce errores de memoria o es incapaz de ejecutarse completamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MBSGDClassifier(learning_rate='constant', eta0=0.05, epochs=2000, fit_intercept=True, batch_size=1, tol=0.0, penalty='l2', loss='squared_loss', alpha=0.5) #todo 0\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El regresor MiniBatch tarda demasiado en ejecutarse, con lo cual no es posible determinar si ha dejado de funcionar debido a falta de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBSGDRegressor(learning_rate='constant', eta0=0.05, epochs=2000, fit_intercept=True, batch_size=1, tol=0.0, penalty='l2', loss='squared_loss', alpha=0.5)\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, el regresor por descenso de gradiente normal también se queda parado\n",
    "durante la ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cuml.SGD(learning_rate='constant', eta0=0.005, epochs=2000, fit_intercept=True, batch_size=2,tol=0.0, penalty='none', loss='squared_loss')\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En datasets de cierto tamaño, devuelve el mismo error de tamaño que ya encontramos en otros clasificadores.\n",
    "- En datasets pequeños, devuelve errores 'L-BFGS line search failed' - posible error de memoria o de entrada de datos.\n",
    "- No ha sido posible probar este algoritmo en el entorno de Tesla V100, debido a que este algoritmo aún no estaba implementado en la versión de RAPIDS empleada allí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MulticlassClassifier(LogisticRegression(), strategy='ovo')\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve el mismo error de sort que los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el entorno Tesla V100, usando una versión deprecada de RAPIDS, se obtiene un error de compilación:\n",
    "\n",
    "CompileException: /tmp/tmpgu_vlsfv/9f7780251c2102e5378a204d4a270d95_2.cubin.cu(25): error: expression must have integral or enum type\n",
    "\n",
    "1 error detected in the compilation of \"/tmp/tmpgu_vlsfv/9f7780251c2102e5378a204d4a270d95_2.cubin.cu\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión mediante algoritmos Quasi-Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En el entorno GTX 1060. devuelve el mismo error de sort que los clasificadores.\n",
    "- En el entorno Tesla V100, se ejecuta correctamente, con lo que puede deberse a un error de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = cuml.QN(loss='softmax')\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación mediante soporte de vectores SVC (C-Support Vector Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve el mismo error de sort que los clasificadores. Adicionalmente, sólo soporta clasificación binaria, con lo cual no es usable en el ejemplo de este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='poly', degree=2, gamma='auto', C=1)\n",
    "x_train, x_test, y_train, y_test  = cuml.train_test_split(listings[columns_to_fit], listings['price'], train_size=0.9)\n",
    "x_test_index = x_test.reset_index(drop=True)\n",
    "y_test_index = y_test.reset_index(drop=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_index)\n",
    "y_results = cudf.DataFrame()\n",
    "y_results['prediction'] = predictions\n",
    "y_results['real'] = y_test_index\n",
    "y_results[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
