{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno emplearemos la implementación de RAPIDS del algoritmo de vecinos cercanos (*K-Nearest Neighbors*) para el cálculo de distancias entre puntos de una nube bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: KNN mediante GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones\n",
    "* **os** y **os.path**: importan utilidades de Python para tratamiento de ficheros y comprobación de rutas.\n",
    "* **cudf**, **cupy** y **cuml**: librerías de RAPIDS.\n",
    "* **pandas** y **numpy**: librerías de manejo de DataFrames y gestión numérica, de vectores y tablas. Equivalentes a cudf y cupy respectivamente para CPU.\n",
    "* **sklearn**: librería de manejo de modelos machine learning, equivalente de cuml en CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import cuml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ficheros de utilidades:\n",
    "* **f_northing**: conversión de coordenadas latitud-longitud a norte-este, empleados en manejo de mapas y coordenadas.\n",
    "* **f_northing_numpy**: equivalente de f_northing para estructuras de numpy.\n",
    "* **f_static_data**: funciones para cargar listas de datos estáticos, tales como nombres de ciudades a utilizar desde el directorio /data, columnas a leer por cada fichero CSV, y columnas a usar en el entrenamiento del modelo.\n",
    "* **f_utils**: utilidades de conversión de datos a tipos float32/float64, limpiado de strings de precios, factorización de columnas complejas en mapas numéricos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/f_northing.py\n",
    "%run ../utils/f_northing_numpy.py\n",
    "%run ../utils/f_static_data.py\n",
    "%run ../utils/f_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de datos:\n",
    "* **cities_to_use**: lista de directorios dentro de /data sobre los que leer datasets en formato CSV. Cada directorio es una ciudad, área, estado o país.\n",
    "* **columns_to_use**: lista de columnas a leer dentro de cada CSV. Todas las columnas deben existir y sus nombres deben coincidir.\n",
    "* **columns_to_fit**: lista de columnas a utilizar para el entrenamiento de modelos de machine learning. Nos permite hacer múltiples usos de un dataset sin necesidad de leerlo de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cities_to_use = ['sevilla']\n",
    "#cities_to_use = ['shanghai']\n",
    "#cities_to_use = cities_to_use_1()\n",
    "cities_to_use = cities_to_use_2()\n",
    "\n",
    "columns_to_use = ['host_id', 'host_response_rate', 'host_acceptance_rate',\n",
    "                  'latitude', 'longitude', 'accommodates', 'price', 'number_of_reviews', 'reviews_per_month',\n",
    "                 'neighbourhood_cleansed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataFrame **listings** representa el conjunto de datos final sobre el que realizar operaciones de ciencia de datos o machine learning. Por cada directorio de datos, leemos todos los ficheros CSV disponibles y los agregamos a **listings**.\n",
    "* **standard_object_type**: algunas columnas no tienen un formato único de datos; esto puede deberse a diferentes departamentos o metodologías empleadas durante los varios *scraping* de datos de la fuente. Esta función convierte columnas (detectadas manualmente a priori) en tipo genérico *object*, que después convertiremos a un tipo de datos más apropiado para nuestro uso.\n",
    "* **drop_duplicates**: dado que utilizamos múltiples *datasets* por ciudades, hay listados de AirBnB que no cambian durante varios meses. En este caso, no necesitamos datos redundantes, y los removemos del DataFrame final.\n",
    "* **reset_index**: los datos de cada fichero se han unido mediante un DataFrame diferente, y por lo tanto los índices del DataFrame quedan mezclados al final del proceso. Con esta instrucción forzamos el índice de **listings** a ordenarse. La instrución añade una columna adicional con el índice antiguo, que podemos obviar con el parámetro drop=**True**.\n",
    "* **shape**: instrucción que devuelve el tamaño completo del DataFrame en formato (filas, columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = cudf.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df = cudf.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings.size == 0:\n",
    "                    listings = temp_df\n",
    "                else:\n",
    "                    for column in listings.columns:\n",
    "                        if listings[column].dtype != temp_df[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings[column].dtype.name+' doesnt match '+temp_df[column].dtype.name)\n",
    "                    listings = listings.append(temp_df)\n",
    "                    \n",
    "listings = listings.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento simple:\n",
    "* **type_conversion**: convertimos todas las columnas a un tipo de datos común: *float32* y *float64* son los más aceptados por los algoritmos de RAPIDS.\n",
    "* **column_factorize**: dado que algunos algoritmos no suportan datos no numéricos, factorizamos las columnas de texto. La operación factorize() convierte una columna con valores no numéricos a un mapa en el que cada valor único se representa por un integer. En nuestro caso, no necesitaremos el mapa que reconoce cada valor, pero es posible usarlo para devolver formato a los datos de cara a estudio o representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_conversion(listings, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings, ['neighbourhood_cleansed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento de cadenas:\n",
    "* **clean_format_strings**: eliminamos el carácter '%' de campos que lo contienen, y convertimos el valor resultante a *float32*.\n",
    "* **clean_format_price**: similar a la función anterior, pero eliminando caracteres de moneda (en nuestro caso, '$' y la coma de cantidades numéricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_format_strings(listings, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price(listings, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fin de visualizar los datos en un formato 2D similar a un mapa, convertimos las coordatas latitud-longitud en distancias norte-este, y les asignamos columnas nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_lat = cp.asarray(listings['latitude'])\n",
    "cupy_long = cp.asarray(listings['longitude'])\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "listings['northing'] = cudf.Series(n_cupy_array).astype('float32')\n",
    "listings['easting'] = cudf.Series(e_cupy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de las primeras 5 filas, para verificar el tratamiento de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de un algoritmo KNN para calcular distancias entre listados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KNN* es un algoritmo de búsqueda de distancias entre puntos. En nuestro caso, dado que utilizaremos coordenadas reales de un mapa, estas distancias pueden usarse en contextos geográficos.\n",
    "\n",
    "Emplearemos dos conjuntos de datos separados, uno con listados baratos (*listings_cheap*) sobre el que entrenaremos el modelo, y uno con listados más caros (*listings_expensive*) sobre el que probaremos el modelo, para recibir los listados más baratos cercanos a cada listado caro.\n",
    "\n",
    "Parámetros:\n",
    "* **n_neighbors**: especifica cuántos vecinos el modelo debe buscar sobre cada punto del *dataset*.\n",
    "\n",
    "Funciones:\n",
    "* **fit**: ejecución del algoritmo *KNN* sobre el conjunto de datos indicado.\n",
    "* **kneighbors**: busca sobre el modelo entrenado los K vecinos más cercanos del conjunto de datos que se introduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn = cuml.NearestNeighbors(n_neighbors=3)\n",
    "listings_cheap = listings[listings['price'] <= 50.0].reset_index(drop=True)\n",
    "listings_expensive = listings[listings['price'] >= 100.0].reset_index(drop=True)\n",
    "listings_cheap_cols = listings_cheap[['easting', 'northing']]\n",
    "listings_expensive_cols = listings_expensive[['easting', 'northing']]\n",
    "knn.fit(listings_cheap_cols)\n",
    "distances, indices = knn.kneighbors(listings_expensive_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto **distances** devuelve las distancias de cada punto del conjunto de prueba a los K vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto **indices** devuelve los índices de los puntos del conjunto de entrenamiento cuyas distancias quedan comprendidas en **distances**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2: KNN mediante CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lectura y tratamiento de los datos iniciales sigue el mismo proceso que para GPU:\n",
    "1. Creamos un nuevo DataFrame vacío.\n",
    "2. Recorremos los directorios disponibles.\n",
    "3. Agregamos los CSV, convirtiendo columnas dispares a tipo *object* si fuera necesario.\n",
    "4. Eliminamos duplicados.\n",
    "5. Reordenamos el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cpu = pd.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df_cpu = pd.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df_cpu, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings_cpu.size == 0:\n",
    "                    listings_cpu = temp_df_cpu\n",
    "                else:\n",
    "                    for column in listings_cpu.columns:\n",
    "                        if listings_cpu[column].dtype != temp_df_cpu[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings_cpu[column].dtype.name+' doesnt match '+temp_df_cpu[column].dtype.name)\n",
    "                    listings_cpu = listings_cpu.append(temp_df_cpu)\n",
    "                    \n",
    "listings_cpu = listings_cpu.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones **type_conversion**, **column_factorize** y **clean_format_strings** son las mismas empleadas para GPU, ya que las operaciones subyacentes tienen la misma semántica y uso para cuDF/cupy como para pandas/numpy.\n",
    "\n",
    "* **clean_format_price_cpu**: versión específica del tratado de cadenas de precios para CPU. Es necesario cambiar ligeramente el órden y número de operaciones para que numpy pueda ejecutar el mismo reemplazo de cadenas de precios que en GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_conversion(listings_cpu, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings_cpu, ['neighbourhood_cleansed'])\n",
    "\n",
    "clean_format_strings(listings_cpu, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price_cpu(listings_cpu, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única diferencia en la conversión de coordenadas latitud-logitud a norte-este es que utilizamos funciones aritméticas provistas por numpy en lugar de cupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_lat = listings_cpu['latitude'].to_numpy()\n",
    "numpy_long = listings_cpu['longitude'].to_numpy()\n",
    "n_numpy_array, e_numpy_array = latlong2osgbgrid_numpy(numpy_lat, numpy_long)\n",
    "listings_cpu['northing'] = pd.Series(n_numpy_array).astype('float32')\n",
    "listings_cpu['easting'] = pd.Series(e_numpy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cpu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de scikit-learn de *KNN* es idéntica en nuestro ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_cpu = NearestNeighbors(n_neighbors=3)\n",
    "listings_cheap_cpu = listings_cpu[listings_cpu['price'] <= 50.0].reset_index(drop=True)\n",
    "listings_expensive_cpu = listings_cpu[listings_cpu['price'] >= 100.0].reset_index(drop=True)\n",
    "listings_cheap_cols_cpu = listings_cheap_cpu[['easting', 'northing']]\n",
    "listings_expensive_cols_cpu = listings_expensive_cpu[['easting', 'northing']]\n",
    "knn_cpu.fit(listings_cheap_cols_cpu)\n",
    "distances_cpu, indices_cpu = knn_cpu.kneighbors(listings_expensive_cols_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
