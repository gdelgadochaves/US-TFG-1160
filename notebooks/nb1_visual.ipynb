{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este cuaderno es simplemente demostrar el uso de las librerías de manipulación de datos de RAPIDS: **cuDF** para la gestión de DataFrames, **cupy** para el manejo de datos y operaciones de transformación y cálculo con los valores de los DataFrames y **cuXfilter** para la visualización de datos en gráficas. Los puntos principales a desarrollar son:\n",
    "* Lectura de datos en formato CSV y agregación en un conjunto de desarrollo (para futuros usos de tratamiento/ciencia de datos o machine learning).\n",
    "* Manipulación básica de datos (operaciones simples sobre columnas).\n",
    "* Manipulación compleja de datos (manipulación de cadenas de texto, transformaciones aritméticas y/o geográficas).\n",
    "* Creación y visualización de mapas de datos en dos dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: Carga y manipulación de datos en GPU con RAPIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones\n",
    "* **os** y **os.path**: importan utilidades de Python para tratamiento de ficheros y comprobación de rutas.\n",
    "* **cudf** y **cupy**: librerías de RAPIDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import cudf\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ficheros de utilidades:\n",
    "* **f_northing**: conversión de coordenadas latitud-longitud a norte-este, empleados en manejo de mapas y coordenadas.\n",
    "* **f_northing_numpy**: equivalente de f_northing para estructuras de numpy.\n",
    "* **f_static_data**: funciones para cargar listas de datos estáticos, tales como nombres de ciudades a utilizar desde el directorio /data, columnas a leer por cada fichero CSV, y columnas a usar en el entrenamiento del modelo.\n",
    "* **f_utils**: utilidades de conversión de datos a tipos float32/float64, limpiado de strings de precios, factorización de columnas complejas en mapas numéricos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/f_northing.py\n",
    "%run ../utils/f_northing_numpy.py\n",
    "%run ../utils/f_static_data.py\n",
    "%run ../utils/f_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de datos:\n",
    "* **cities_to_use**: lista de directorios dentro de /data sobre los que leer datasets en formato CSV. Cada directorio es una ciudad, área, estado o país.\n",
    "* **columns_to_use**: lista de columnas a leer dentro de cada CSV. Todas las columnas deben existir y sus nombres deben coincidir.\n",
    "* **columns_to_fit**: lista de columnas a utilizar para el entrenamiento de modelos de machine learning. Nos permite hacer múltiples usos de un dataset sin necesidad de leerlo de nuevo.\n",
    "\n",
    "Los datos han sido obtenidos del [repositorio público de AirBnB](http://insideairbnb.com/get-the-data.html), por cada ciudad se utilizan todos los datasets de listados (listings.tar.gz) disponibles para el año 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_to_use = ['sevilla']\n",
    "#cities_to_use = ['shanghai']\n",
    "#cities_to_use = cities_to_use_1()\n",
    "#cities_to_use = cities_to_use_2()\n",
    "\n",
    "columns_to_use = ['host_id', 'host_response_rate', 'host_acceptance_rate', 'latitude', 'longitude', \n",
    "                  'accommodates', 'price', 'number_of_reviews', 'reviews_per_month', 'neighbourhood_cleansed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la cantidad de diferentes ficheros que debemos leer, y a que los diferentes _scraping_ realizados por el equipo(s) de AirBnB no siempre son iguales, podemos encontrar que en el dataset de algunos meses para algunas ciudades faltan columnas.\n",
    "\n",
    "La siguiente celda recorre las ciudades disponibles y comprueba en qué datasets faltan columnas, dado que las trazas de error de RAPIDS y pandas no siempre son detalladas. El resultado esperado es que no se imprima ninguna línea por la consola, ya que significaría que todos los datasets disponibles tienen las columnas necesarias.\n",
    "\n",
    "Esta celda está desactivada por defecto y es opcional, sólo requerida si se desea comprobar el estado de uno o más ficheros previa ejecución del paso de agregación, o si dicho paso no se ejecuta correctamente."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "             if file.endswith('.csv'):\n",
    "                temp_df_cpu = cudf.read_csv(directory + file)\n",
    "                for column in columns_to_use:\n",
    "                    if(column not in temp_df_cpu.columns):\n",
    "                        print('Missing column ' + column + ' in ' + city + ' -> ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataFrame **listings** representa el conjunto de datos final sobre el que realizar operaciones de ciencia de datos o machine learning. Por cada directorio de datos, leemos todos los ficheros CSV disponibles y los agregamos a **listings**.\n",
    "* **standard_object_type**: algunas columnas no tienen un formato único de datos; esto puede deberse a diferentes departamentos o metodologías empleadas durante los varios *scraping* de datos de la fuente. Esta función convierte columnas (detectadas manualmente a priori) en tipo genérico *object*, que después convertiremos a un tipo de datos más apropiado para nuestro uso.\n",
    "* **drop_duplicates**: dado que utilizamos múltiples *datasets* por ciudades, hay listados de AirBnB que no cambian durante varios meses. En este caso, no necesitamos datos redundantes, y los removemos del DataFrame final.\n",
    "* **reset_index**: los datos de cada fichero se han unido mediante un DataFrame diferente, y por lo tanto los índices del DataFrame quedan mezclados al final del proceso. Con esta instrucción forzamos el índice de **listings** a ordenarse. La instrución añade una columna adicional con el índice antiguo, que podemos obviar con el parámetro drop=**True**.\n",
    "* **shape**: instrucción que devuelve el tamaño completo del DataFrame en formato (filas, columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listings = cudf.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df = cudf.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings.size == 0:\n",
    "                    listings = temp_df\n",
    "                else:\n",
    "                    for column in listings.columns:\n",
    "                        if listings[column].dtype != temp_df[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings[column].dtype.name+' doesnt match '+temp_df[column].dtype.name)\n",
    "                    listings = listings.append(temp_df)\n",
    "                    \n",
    "listings = listings.drop_duplicates().reset_index(drop=True)\n",
    "listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instrucción nvidia-smi nos permite leer la información de uso de la(s) GPU(s) disponible(s). En particular, es útil para controlar cuánta memoria de vídeo (VRAM) está en uso. Dado que RAPIDS carga todos los datos en la GPU para optimizar el acceso a la información, hay que controlar que haya suficiente memoria antes de leer datos.\n",
    "\n",
    "Adicionalmente, algunas técnicas de machine learning requieren espacio libre igual al del *dataset* en uso, ya que lo duplican por completo. Por lo tanto, es aconsejable tener disponible al menos el doble de la memoria empleada por el *dataset* en uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos con cuDF y cuPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento simple:\n",
    "* **type_conversion**: convertimos todas las columnas a un tipo de datos común: *float32* y *float64* son los más aceptados por los algoritmos de RAPIDS.\n",
    "* **column_factorize**: dado que algunos algoritmos no suportan datos no numéricos, factorizamos las columnas de texto. La operación factorize() convierte una columna con valores no numéricos a un mapa en el que cada valor único se representa por un integer. En nuestro caso, no necesitaremos el mapa que reconoce cada valor, pero es posible usarlo para devolver formato a los datos de cara a estudio o representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "type_conversion(listings, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings, ['neighbourhood_cleansed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento de cadenas:\n",
    "* **clean_format_strings**: eliminamos el carácter '%' de campos que lo contienen, y convertimos el valor resultante a *float32*.\n",
    "* **clean_format_price**: similar a la función anterior, pero eliminando caracteres de moneda (en nuestro caso, '$' y la coma de cantidades numéricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_format_strings(listings, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price(listings, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos geográficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fin de visualizar los datos en un formato 2D similar a un mapa, convertimos las coordatas latitud-longitud en distancias norte-este, y les asignamos columnas nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cupy_lat = cp.asarray(listings['latitude'])\n",
    "cupy_long = cp.asarray(listings['longitude'])\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "listings['northing'] = cudf.Series(n_cupy_array).astype('float32')\n",
    "listings['easting'] = cudf.Series(e_cupy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final del tratamiento de datos:\n",
    "* dtypes: tipo de datos de cada columna.\n",
    "* head: visuzalización de las primeras 5 filas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualización de datos se realizará en la sección 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2: Carga y manipulación de datos en CPU con pandas y numPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones\n",
    "* pandas y numpy: librerías de manejo de DataFrames y gestión numérica, de vectores y tablas. Equivalentes a cudf y cupy respectivamente para CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lectura y tratamiento de los datos iniciales sigue el mismo proceso que para GPU:\n",
    "1. Creamos un nuevo DataFrame vacío.\n",
    "2. Recorremos los directorios disponibles.\n",
    "3. Agregamos los CSV, convirtiendo columnas dispares a tipo *object* si fuera necesario.\n",
    "4. Eliminamos duplicados.\n",
    "5. Reordenamos el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listings_cpu = pd.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df_cpu = pd.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df_cpu, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings_cpu.size == 0:\n",
    "                    listings_cpu = temp_df_cpu\n",
    "                else:\n",
    "                    for column in listings_cpu.columns:\n",
    "                        if listings_cpu[column].dtype != temp_df_cpu[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings_cpu[column].dtype.name+' doesnt match '+temp_df_cpu[column].dtype.name)\n",
    "                    listings_cpu = listings_cpu.append(temp_df_cpu)\n",
    "                    \n",
    "listings_cpu = listings_cpu.drop_duplicates().reset_index(drop=True)\n",
    "listings_cpu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones **type_conversion**, **column_factorize** y **clean_format_strings** son las mismas empleadas para GPU, ya que las operaciones subyacentes tienen la misma semántica y uso para cuDF/cupy como para pandas/numpy.\n",
    "\n",
    "* **clean_format_price_cpu**: versión específica del tratado de cadenas de precios para CPU. Es necesario cambiar ligeramente el órden y número de operaciones para que numpy pueda ejecutar el mismo reemplazo de cadenas de precios que en GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "type_conversion(listings_cpu, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings_cpu, ['neighbourhood_cleansed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_format_strings(listings_cpu, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price_cpu(listings_cpu, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos geográficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única diferencia en la conversión de coordenadas latitud-logitud a norte-este es que utilizamos funciones aritméticas provistas por numpy en lugar de cupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "numpy_lat = listings_cpu['latitude'].to_numpy()\n",
    "numpy_long = listings_cpu['longitude'].to_numpy()\n",
    "n_numpy_array, e_numpy_array = latlong2osgbgrid_numpy(numpy_lat, numpy_long)\n",
    "listings_cpu['northing'] = pd.Series(n_numpy_array).astype('float32')\n",
    "listings_cpu['easting'] = pd.Series(e_numpy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cpu.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cpu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando %reset nos permite limpiar todas las variables sin reiniciar el kernel. Esto nos permite aprovechar al máximo la gestión de memoria inicializada por RAPIDS, ejecutando pruebas múltiples veces en el mismo kernel inicializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 3: Visualización de resultados mediante cuXfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería cuXfilter nos permite visualizar datos gráficamente. Vamos a visualizar los listados de AirBnB en las ciudades seleccionadas durante el año 2020, con un selector por distritos/barrios."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cuxfilter as cxf\n",
    "\n",
    "neighborhood_map = dict(zip(range(len(neighborhood_names)), neighborhood_names.values_host))\n",
    "cxf_data = cxf.DataFrame.from_dataframe(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un gráfico de tipo *scatter* para visualizar puntos en una escala 2D (en este caso marcada por las coordenadas norte-este), así como un *widget* donde escribimos los nombres de las zonas disponibles. Podremos seleccionar cada zona y ver los listados específicos.\n",
    "\n",
    "***Nota:*** es necesario guardar el resultado de aplicar la operación **factorize** de cuDF/pandas sobre la columna 'neighbourhood_cleansed', lo cual no está soportado por las funciones de utilidad. Si se desea ejecutar este mapa, es necesario aplicar la operación manualmente en el notebook."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chart_width = 600\n",
    "scatter_chart = cxf.charts.datashader.scatter(x='easting', y='northing', \n",
    "                                              width=chart_width, \n",
    "                                              height=int((listings['easting'].max() - listings['easting'].min()) / \n",
    "                                                         (listings['northing'].max() - listings['northing'].min()) *\n",
    "                                                          chart_width))\n",
    "\n",
    "widget = cxf.charts.panel_widgets.multi_select('neighbourhood_cleansed', label_map=neighborhood_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos el gráfico en un *dashboard* creado en el navegador:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dashboard = cxf_data.dashboard([scatter_chart, widget], theme=cxf.themes.dark, data_size_widget=True)\n",
    "dashboard.show('http://localhost', port=8789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el gráfico sin abrir un widget podemos usar el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scatter_chart.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detener la ejecución del gráfico, podemos usar el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dashboard.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
