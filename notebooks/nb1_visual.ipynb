{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: Carga y manipulación de datos en GPU con RAPIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "%run ../utils/f_static_data.py\n",
    "%run ../utils/f_northing.py\n",
    "%run ../utils/f_northing_numpy.py\n",
    "%run ../utils/f_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el tamaño de muestra que deseemos estudiar, podemos cargar uno o múltiples datasets en memoria. Para evitar discrepancias en el número de columnas, seleccionamos manualmente las que nos interesan.\n",
    "\n",
    "Los datos han sido obtenidos del repositorio público de AirBnB: http://insideairbnb.com/get-the-data.html, por cada ciudad se utilizan todos los datasets de listados (listings.tar.gz) disponibles para el año 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_to_use = ['sevilla']\n",
    "#cities_to_use = ['shanghai']\n",
    "#cities_to_use = cities_to_use_1()\n",
    "#cities_to_use = cities_to_use_2()\n",
    "\n",
    "columns_to_use = ['host_id', 'host_response_rate', 'host_acceptance_rate', 'latitude', 'longitude', \n",
    "                  'accommodates', 'price', 'number_of_reviews', 'reviews_per_month', 'neighbourhood_cleansed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la cantidad de diferentes ficheros que debemos leer, y a que los diferentes _scraping_ realizados por el equipo(s) de AirBnB no siempre son iguales, podemos encontrar que en el dataset de algunos meses para algunas ciudades faltan columnas.\n",
    "\n",
    "La siguiente celda recorre las ciudades disponibles y comprueba en qué datasets faltan columnas, dado que las trazas de error de RAPIDS y pandas no siempre son detalladas. El resultado esperado es que no se imprima ninguna línea por la consola, ya que significaría que todos los datasets disponibles tienen las columnas necesarias."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "             if file.endswith('.csv'):\n",
    "                temp_df_cpu = cudf.read_csv(directory + file)\n",
    "                for column in columns_to_use:\n",
    "                    if(column not in temp_df_cpu.columns):\n",
    "                        print('Missing column ' + column + ' in ' + city + ' -> ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos en memoria los datasets que vayamos a utilizar y los compilamos en uno. Convertimos columnas con tipos de datos dispares de modo que puedan ser almacenadas en un solo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listings = cudf.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df = cudf.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings.size == 0:\n",
    "                    listings = temp_df\n",
    "                else:\n",
    "                    for column in listings.columns:\n",
    "                        if listings[column].dtype != temp_df[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings[column].dtype.name+' doesnt match '+temp_df[column].dtype.name)\n",
    "                    listings = listings.append(temp_df)\n",
    "                    \n",
    "listings = listings.drop_duplicates().reset_index(drop=True)\n",
    "listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instrucción nvidia-smi nos permite leer la información de uso de la(s) GPU(s) disponible(s). En particular, es útil para controlar cuánta memoria de vídeo (VRAM) está en uso. Dado que RAPIDS carga todos los datos en la GPU para optimizar el acceso a la información, hay que controlar que haya suficiente memoria antes de leer datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos con cuDF y cuPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos todas las columnas a un tipo de datos común: float32 es el más aceptado por los algoritmos de RAPIDS.\n",
    "\n",
    "Dado que algunos algoritmos no suportan datos no numéricos, factorizamos las columnas de texto. La operación factorize() convierte una columna con valores no numéricos a un mapa en el que cada valor único se representa por un integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "type_conversion(listings, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings, ['neighbourhood_cleansed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En columnas con texto no deseado (como precios con símbolos de moneda), limpiamos caracteres no deseados y convertimos valores nulos. Finalmente, convertimos todo a dtype float32 para mantener la consistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_format_strings(listings, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price(listings, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos geográficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos las coordenadas de longitud y latitud a distancias norte y este, a fin de normalizar la escala de los gráficos. La función de conversión (con su fuente de referencia) se encuentra en un fichero de utilidad aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cupy_lat = cp.asarray(listings['latitude'])\n",
    "cupy_long = cp.asarray(listings['longitude'])\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "listings['northing'] = cudf.Series(n_cupy_array).astype('float32')\n",
    "listings['easting'] = cudf.Series(e_cupy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final del tratamiento de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2: Carga y manipulación de datos en CPU con pandas y numPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "listings_cpu = pd.DataFrame()\n",
    "\n",
    "for city in cities_to_use:\n",
    "    directory = '../data/' + city + '/'\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                temp_df_cpu = pd.read_csv(directory + file, usecols = columns_to_use)\n",
    "                standard_object_type(temp_df_cpu, ['host_acceptance_rate', 'neighbourhood_cleansed'])\n",
    "                if listings_cpu.size == 0:\n",
    "                    listings_cpu = temp_df_cpu\n",
    "                else:\n",
    "                    for column in listings_cpu.columns:\n",
    "                        if listings_cpu[column].dtype != temp_df_cpu[column].dtype:\n",
    "                            print('Found error: '+column+' type '+listings_cpu[column].dtype.name+' doesnt match '+temp_df_cpu[column].dtype.name)\n",
    "                    listings_cpu = listings_cpu.append(temp_df_cpu)\n",
    "                    \n",
    "listings_cpu = listings_cpu.drop_duplicates().reset_index(drop=True)\n",
    "listings_cpu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "type_conversion(listings_cpu, ['host_id', 'accommodates', 'number_of_reviews', 'reviews_per_month'])\n",
    "column_factorize(listings_cpu, ['neighbourhood_cleansed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_format_strings(listings_cpu, ['host_response_rate', 'host_acceptance_rate'])\n",
    "clean_format_price_cpu(listings_cpu, ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos geográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "numpy_lat = listings_cpu['latitude'].to_numpy()\n",
    "numpy_long = listings_cpu['longitude'].to_numpy()\n",
    "n_numpy_array, e_numpy_array = latlong2osgbgrid_numpy(numpy_lat, numpy_long)\n",
    "listings_cpu['northing'] = pd.Series(n_numpy_array).astype('float32')\n",
    "listings_cpu['easting'] = pd.Series(e_numpy_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando %reset nos permite limpiar todas las variables sin reiniciar el kernel. Esto nos permite aprovechar al máximo la gestión de memoria inicializada por RAPIDS, ejecutando pruebas múltiples veces en el mismo kernel inicializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 3: Visualización de resultados mediante cuXfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería cuXfilter nos permite visualizar datos gráficamente. Vamos a visualizar los listados de AirBnB en Sevilla a 29 de octubre de 2020, con un selector por zonas."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cuxfilter as cxf\n",
    "\n",
    "neighborhood_map = dict(zip(range(len(neighborhood_names)), neighborhood_names.values_host))\n",
    "cxf_data = cxf.DataFrame.from_dataframe(listings)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chart_width = 600\n",
    "scatter_chart = cxf.charts.datashader.scatter(x='easting', y='northing', \n",
    "                                              width=chart_width, \n",
    "                                              height=int((listings['easting'].max() - listings['easting'].min()) / \n",
    "                                                         (listings['northing'].max() - listings['northing'].min()) *\n",
    "                                                          chart_width))\n",
    "\n",
    "widget = cxf.charts.panel_widgets.multi_select('neighbourhood_cleansed', label_map=neighborhood_map)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dashboard = cxf_data.dashboard([scatter_chart, widget], theme=cxf.themes.dark, data_size_widget=True)\n",
    "dashboard.show('http://localhost', port=8789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el gráfico sin abrir un widget podemos usar el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scatter_chart.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detener la ejecución del gráfico, podemos usar el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dashboard.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
